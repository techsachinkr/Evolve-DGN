{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6FAG8Y3ordOt",
    "outputId": "c2aa01de-039b-404b-a8a8-526227e98648"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.12.14)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.7.14)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.14.1)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch_geometric\n",
      "Successfully installed torch_geometric-2.6.1\n",
      "Collecting torch_geometric_temporal\n",
      "  Downloading torch_geometric_temporal-0.56.2-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric_temporal) (4.4.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torch_geometric_temporal) (2.6.0+cu124)\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from torch_geometric_temporal) (3.0.12)\n",
      "Collecting torch-sparse (from torch_geometric_temporal)\n",
      "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting torch-scatter (from torch_geometric_temporal)\n",
      "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (from torch_geometric_temporal) (2.6.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric_temporal) (2.0.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch_geometric_temporal) (3.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (4.14.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (2025.3.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->torch_geometric_temporal)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->torch_geometric_temporal)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->torch_geometric_temporal)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->torch_geometric_temporal)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->torch_geometric_temporal)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->torch_geometric_temporal)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->torch_geometric_temporal)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->torch_geometric_temporal)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->torch_geometric_temporal)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->torch_geometric_temporal)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torch_geometric_temporal) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torch_geometric_temporal) (1.3.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric->torch_geometric_temporal) (3.12.14)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric->torch_geometric_temporal) (5.9.5)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric->torch_geometric_temporal) (3.2.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric->torch_geometric_temporal) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric->torch_geometric_temporal) (4.67.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse->torch_geometric_temporal) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->torch_geometric_temporal) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->torch_geometric_temporal) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->torch_geometric_temporal) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->torch_geometric_temporal) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->torch_geometric_temporal) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->torch_geometric_temporal) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->torch_geometric_temporal) (1.20.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torch_geometric_temporal) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->torch_geometric_temporal) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->torch_geometric_temporal) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->torch_geometric_temporal) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->torch_geometric_temporal) (2025.7.14)\n",
      "Downloading torch_geometric_temporal-0.56.2-py3-none-any.whl (102 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.3/102.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: torch-scatter, torch-sparse\n",
      "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp311-cp311-linux_x86_64.whl size=547368 sha256=769da123feabf5dc4a55d257d640ab46ccf0322562998dcf1dfd62071ead86dc\n",
      "  Stored in directory: /root/.cache/pip/wheels/b8/d4/0e/a80af2465354ea7355a2c153b11af2da739cfcf08b6c0b28e2\n",
      "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp311-cp311-linux_x86_64.whl size=1127937 sha256=24807eeaae7e460ffb4a00c1f3adfba881d03aaeeec130655fcb532e97fe8f5d\n",
      "  Stored in directory: /root/.cache/pip/wheels/75/e2/1e/299c596063839303657c211f587f05591891cc6cf126d94d21\n",
      "Successfully built torch-scatter torch-sparse\n",
      "Installing collected packages: torch-scatter, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, torch-sparse, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch_geometric_temporal\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch-scatter-2.1.2 torch-sparse-0.6.18 torch_geometric_temporal-0.56.2\n",
      "Collecting stable_baselines3\n",
      "  Downloading stable_baselines3-2.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: gymnasium<1.3.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.2.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.0.2)\n",
      "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.6.0+cu124)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.1.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.10.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable_baselines3) (4.14.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.3.0,>=0.29.1->stable_baselines3) (0.0.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.18.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n",
      "Downloading stable_baselines3-2.7.0-py3-none-any.whl (187 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: stable_baselines3\n",
      "Successfully installed stable_baselines3-2.7.0\n",
      "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (2.0.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.14.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_geometric\n",
    "!pip install torch_geometric_temporal\n",
    "!pip install stable_baselines3\n",
    "!pip install gymnasium\n",
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FnFibSg5reCi"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Functionality: environment\n",
    "# Description: A simplified, Gymnasium-compatible environment for disaster response simulation.\n",
    "# ==============================================================================\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from gymnasium import spaces\n",
    "import collections\n",
    "\n",
    "class DisasterEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    A simplified simulation of a disaster environment.\n",
    "\n",
    "    The state is represented by a dynamic graph where nodes are locations\n",
    "    (demand, supply, hospitals) and edges are transportation routes.\n",
    "    Node features include demand/supply levels. Edge features include travel time.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_demand_nodes=10, num_supply_nodes=3, num_hospitals=2):\n",
    "        super(DisasterEnv, self).__init__()\n",
    "        self.num_demand_nodes = num_demand_nodes\n",
    "        self.num_supply_nodes = num_supply_nodes\n",
    "        self.num_hospitals = num_hospitals\n",
    "        self.num_nodes = num_demand_nodes + num_supply_nodes + num_hospitals\n",
    "        self.timestep = 0\n",
    "        self.max_timesteps = 100\n",
    "\n",
    "        # Define action and observation space\n",
    "        # Action for each supply agent: target_node.\n",
    "        # This is a MultiDiscrete space where each of the `num_supply_nodes` agents\n",
    "        # chooses one of the `num_demand_nodes` to send resources to.\n",
    "        self.num_agents = self.num_supply_nodes\n",
    "        self.action_space = spaces.MultiDiscrete([self.num_demand_nodes] * self.num_agents)\n",
    "\n",
    "        # Observation space: Using a Dict space to pass graph components to the GNN policy\n",
    "        self.observation_space = spaces.Dict({\n",
    "            \"node_features\": spaces.Box(low=-np.inf, high=np.inf, shape=(self.num_nodes, 3), dtype=np.float32),\n",
    "            \"adj_matrix\": spaces.Box(low=0, high=np.inf, shape=(self.num_nodes, self.num_nodes), dtype=np.float32)\n",
    "        })\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.timestep = 0\n",
    "        self._initialize_graph()\n",
    "        obs = self._get_observation()\n",
    "        info = {}\n",
    "        return obs, info\n",
    "\n",
    "    def _initialize_graph(self):\n",
    "        # Create a connected graph\n",
    "        self.graph = nx.watts_strogatz_graph(self.num_nodes, k=4, p=0.5, seed=self.np_random)\n",
    "\n",
    "        # Correctly track total demand generated within an episode\n",
    "        self.total_demand_generated_this_episode = 0\n",
    "\n",
    "        # Assign node types and initial features\n",
    "        for i in range(self.num_nodes):\n",
    "            if i < self.num_demand_nodes:\n",
    "                self.graph.nodes[i]['type'] = 'demand'\n",
    "                initial_demand = self.np_random.uniform(50, 100)\n",
    "                self.graph.nodes[i]['initial_demand'] = initial_demand\n",
    "                self.graph.nodes[i]['total_demand_for_node'] = initial_demand\n",
    "                self.graph.nodes[i]['demand'] = initial_demand\n",
    "                self.graph.nodes[i]['priority'] = self.np_random.uniform(0.5, 1.0)\n",
    "                self.graph.nodes[i]['met_demand'] = 0\n",
    "                self.total_demand_generated_this_episode += initial_demand\n",
    "            elif i < self.num_demand_nodes + self.num_supply_nodes:\n",
    "                self.graph.nodes[i]['type'] = 'supply'\n",
    "                # Increase supply to make the scenario solvable\n",
    "                self.graph.nodes[i]['supply'] = self.np_random.uniform(3000, 4000)\n",
    "                self.graph.nodes[i]['demand'] = 0\n",
    "                self.graph.nodes[i]['priority'] = 0\n",
    "                self.graph.nodes[i]['met_demand'] = 0\n",
    "            else:\n",
    "                self.graph.nodes[i]['type'] = 'hospital'\n",
    "                self.graph.nodes[i]['capacity'] = self.np_random.uniform(20, 50)\n",
    "                self.graph.nodes[i]['demand'] = 0\n",
    "                self.graph.nodes[i]['supply'] = 0\n",
    "                self.graph.nodes[i]['met_demand'] = 0\n",
    "                self.graph.nodes[i]['priority'] = 1.0\n",
    "\n",
    "        # Initialize edge attributes (travel time)\n",
    "        for u, v in self.graph.edges():\n",
    "            self.graph.edges[u, v]['travel_time'] = self.np_random.uniform(1, 5)\n",
    "            self.graph.edges[u, v]['initial_travel_time'] = self.graph.edges[u, v]['travel_time']\n",
    "            self.graph.edges[u,v]['status'] = 'ok' # Add status for degradation\n",
    "\n",
    "    def _get_observation(self):\n",
    "        node_features_list = []\n",
    "        for i in range(self.num_nodes):\n",
    "            node = self.graph.nodes[i]\n",
    "            if node['type'] == 'demand':\n",
    "                features = [node['demand'], node['met_demand'], node['priority']]\n",
    "            elif node['type'] == \"supply\":\n",
    "                features = [0, node['supply'], 0]  # Pad with a 0 to match other feature lengths\n",
    "            else: # hospital\n",
    "                features = [node['demand'], node['capacity'], node['priority']]\n",
    "            node_features_list.append(features)\n",
    "\n",
    "        node_features = np.array(node_features_list, dtype=np.float32)\n",
    "        adj_matrix = nx.to_numpy_array(self.graph, weight='travel_time').astype(np.float32)\n",
    "\n",
    "        return {\"node_features\": node_features, \"adj_matrix\": adj_matrix}\n",
    "\n",
    "    def step(self, action):\n",
    "        self.timestep += 1\n",
    "\n",
    "        total_demand_before = sum(d['demand'] for i, d in self.graph.nodes(data=True) if d['type'] == 'demand')\n",
    "\n",
    "        # 1. Execute actions\n",
    "        dispatches = []\n",
    "        supply_node_indices = range(self.num_demand_nodes, self.num_demand_nodes + self.num_supply_nodes)\n",
    "\n",
    "        for agent_idx, target_node_idx in enumerate(action):\n",
    "            supply_node_idx = supply_node_indices[agent_idx]\n",
    "\n",
    "            if target_node_idx >= self.num_demand_nodes: continue\n",
    "\n",
    "            # Increase dispatch amount for more impact\n",
    "            dispatch_amount = 75\n",
    "            if self.graph.nodes[supply_node_idx]['supply'] >= dispatch_amount:\n",
    "                self.graph.nodes[supply_node_idx]['supply'] -= dispatch_amount\n",
    "\n",
    "                demand_node = self.graph.nodes[target_node_idx]\n",
    "                satisfied_amount = min(demand_node['demand'], dispatch_amount)\n",
    "                demand_node['demand'] -= satisfied_amount\n",
    "                demand_node['met_demand'] += satisfied_amount\n",
    "\n",
    "                travel_time = 100\n",
    "                if self.graph.has_edge(supply_node_idx, target_node_idx):\n",
    "                    travel_time = self.graph.edges[supply_node_idx, target_node_idx]['travel_time']\n",
    "\n",
    "                dispatches.append({'amount': satisfied_amount, 'travel_time': travel_time})\n",
    "\n",
    "        # 2. Simulate disaster progression\n",
    "        self._update_environment()\n",
    "\n",
    "        # 3. Calculate reward\n",
    "        reward = self._calculate_reward(dispatches, total_demand_before)\n",
    "\n",
    "        done = self.timestep >= self.max_timesteps or total_demand_before <= 0\n",
    "        obs = self._get_observation()\n",
    "        info = {'dispatches': dispatches}\n",
    "\n",
    "        return obs, reward, done, False, info\n",
    "\n",
    "    def _update_environment(self):\n",
    "        # More complex environmental changes\n",
    "        for u, v in list(self.graph.edges()):\n",
    "            # Degrade roads before they fail\n",
    "            if self.graph.edges[u,v]['status'] == 'ok' and self.np_random.random() < 0.1:\n",
    "                self.graph.edges[u,v]['travel_time'] *= self.np_random.uniform(1.5, 2.5)\n",
    "                self.graph.edges[u,v]['status'] = 'degraded'\n",
    "            # Fail degraded roads\n",
    "            elif self.graph.edges[u,v]['status'] == 'degraded' and self.np_random.random() < 0.2:\n",
    "                 self.graph.remove_edge(u,v)\n",
    "\n",
    "        for i in range(self.num_demand_nodes):\n",
    "            if self.np_random.random() < 0.2:\n",
    "                surge_amount = self.np_random.uniform(30, 60)\n",
    "                self.graph.nodes[i]['demand'] += surge_amount\n",
    "                self.total_demand_generated_this_episode += surge_amount\n",
    "                self.graph.nodes[i]['total_demand_for_node'] += surge_amount\n",
    "\n",
    "    def _calculate_reward(self, dispatches, total_demand_before):\n",
    "        total_demand_after = sum(d['demand'] for i, d in self.graph.nodes(data=True) if d['type'] == 'demand')\n",
    "\n",
    "        # Effectiveness: Reward for reducing demand\n",
    "        effectiveness_reward = (total_demand_before - total_demand_after)\n",
    "\n",
    "        # Timeliness: Penalize for travel time\n",
    "        timeliness_penalty = sum(d['travel_time'] for d in dispatches)\n",
    "\n",
    "        # Equity: Use Jain's Fairness Index\n",
    "        demand_nodes_data = [self.graph.nodes[i] for i in range(self.num_demand_nodes)]\n",
    "        demand_met_fractions = [(d['met_demand'] / (d['total_demand_for_node'] + 1e-8)) for d in demand_nodes_data]\n",
    "        equity_reward = jain_fairness_index(demand_met_fractions)\n",
    "\n",
    "        # Unmet Demand Penalty: A strong signal to serve everyone\n",
    "        unmet_demand_penalty = total_demand_after\n",
    "\n",
    "        # Final weighted reward\n",
    "        w_eff, w_time, w_eq, w_unmet = 2.0, -0.05, 250.0, -0.5\n",
    "        return (w_eff * effectiveness_reward +\n",
    "                w_time * timeliness_penalty +\n",
    "                w_eq * equity_reward +\n",
    "                w_unmet * unmet_demand_penalty)\n",
    "\n",
    "def jain_fairness_index(allocations):\n",
    "    allocations = np.clip(np.array(allocations), 0, 1)\n",
    "    if len(allocations) == 0 or np.sum(allocations) == 0: return 0.0\n",
    "    return (np.sum(allocations)**2) / (len(allocations) * np.sum(allocations**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nJx8601tsEiI"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Functionality: models\n",
    "# Description: PyTorch models for Evolve-DGN, including a true GNN policy.\n",
    "# ==============================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from gymnasium import spaces\n",
    "\n",
    "class GNNFeatureExtractor(BaseFeaturesExtractor):\n",
    "    \"\"\"\n",
    "    A GNN-based feature extractor for the PPO agent.\n",
    "    It uses a Graph Attention Network (GAT) to process the graph structure.\n",
    "    \"\"\"\n",
    "    def __init__(self, observation_space: spaces.Dict, features_dim: int = 128):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "\n",
    "        node_input_dim = observation_space[\"node_features\"].shape[1]\n",
    "        num_supply_nodes = 3 # Hardcoded for simplicity, should match env\n",
    "\n",
    "        # The final features_dim will be the GNN output + features for each supply node\n",
    "        gnn_output_dim = 64\n",
    "        final_features_dim = gnn_output_dim + (num_supply_nodes * node_input_dim)\n",
    "        self._features_dim = final_features_dim\n",
    "\n",
    "        self.gat_conv1 = GATConv(node_input_dim, 32, heads=2, concat=True)\n",
    "        self.gat_conv2 = GATConv(32 * 2, gnn_output_dim, heads=1, concat=False)\n",
    "\n",
    "    def forward(self, observations: dict) -> torch.Tensor:\n",
    "        node_features_batch = observations[\"node_features\"]\n",
    "        adj_matrix_batch = observations[\"adj_matrix\"]\n",
    "\n",
    "        batch_size = node_features_batch.shape[0]\n",
    "        processed_batches = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            node_features = node_features_batch[i]\n",
    "            adj_matrix = adj_matrix_batch[i]\n",
    "\n",
    "            edge_index = adj_matrix.nonzero().t().contiguous()\n",
    "\n",
    "            x = F.relu(self.gat_conv1(node_features, edge_index))\n",
    "            x = self.gat_conv2(x, edge_index)\n",
    "\n",
    "            graph_embedding = x.mean(dim=0)\n",
    "\n",
    "            # Extract supply node features (indices 10, 11, 12)\n",
    "            supply_node_features = node_features[10:13].flatten()\n",
    "\n",
    "            # Concatenate global graph embedding with local supply features\n",
    "            combined_features = torch.cat([graph_embedding, supply_node_features])\n",
    "            processed_batches.append(combined_features)\n",
    "\n",
    "        return torch.stack(processed_batches)\n",
    "\n",
    "class ActorCriticGNNPolicy(ActorCriticPolicy):\n",
    "    \"\"\"\n",
    "    A custom policy that uses the GNNFeatureExtractor.\n",
    "    \"\"\"\n",
    "    def __init__(self, observation_space, action_space, lr_schedule, **kwargs):\n",
    "        super().__init__(\n",
    "            observation_space,\n",
    "            action_space,\n",
    "            lr_schedule,\n",
    "            features_extractor_class=GNNFeatureExtractor,\n",
    "            # features_extractor_kwargs are now inferred, no need to pass features_dim\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "# ==============================================================================\n",
    "# Functionality: training\n",
    "# Description: Training loops for Evolve-DGN and baseline models.\n",
    "# ==============================================================================\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "import os\n",
    "import random\n",
    "\n",
    "def train_evolve_dgn_model(env_class, model_name=\"Evolve-DGN_Ours\", total_timesteps=90000):\n",
    "    \"\"\"\n",
    "    Train the advanced Evolve-DGN model using the custom GNN policy.\n",
    "    \"\"\"\n",
    "    log_dir = \"/tmp/gym/\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    vec_env = make_vec_env(lambda: env_class(), n_envs=4)\n",
    "\n",
    "    # Use the superior ActorCriticGNNPolicy\n",
    "    model = PPO(ActorCriticGNNPolicy, vec_env, verbose=0, tensorboard_log=log_dir,\n",
    "                learning_rate=0.0003, n_steps=2048, batch_size=64, n_epochs=10)\n",
    "\n",
    "    print(f\"--- Starting Advanced Training for {model_name} ---\")\n",
    "    model.learn(total_timesteps=total_timesteps)\n",
    "\n",
    "    model_path = f\"{model_name}.zip\"\n",
    "    model.save(model_path)\n",
    "    print(f\"--- Finished Advanced Training for {model_name}, saved to {model_path} ---\")\n",
    "\n",
    "    return model_path, 'gnn_rl' # Return model type for evaluation\n",
    "\n",
    "def train_baseline_rl_model(env_class, model_name, total_timesteps=25000):\n",
    "    \"\"\"\n",
    "    Train a baseline RL model using the simple MlpPolicy.\n",
    "    \"\"\"\n",
    "    log_dir = \"/tmp/gym/\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    vec_env = make_vec_env(env_class, n_envs=4,\n",
    "                           env_kwargs=dict(use_gnn_obs=False)) # Use flattened obs for MLP\n",
    "\n",
    "    model = PPO(\"MlpPolicy\", vec_env, verbose=0, tensorboard_log=log_dir)\n",
    "\n",
    "    print(f\"--- Starting Baseline Training for {model_name} ---\")\n",
    "    model.learn(total_timesteps=total_timesteps)\n",
    "\n",
    "    model_path = f\"{model_name}.zip\"\n",
    "    model.save(model_path)\n",
    "    print(f\"--- Finished Baseline Training for {model_name}, saved to {model_path} ---\")\n",
    "\n",
    "    return model_path, 'mlp_rl'\n",
    "\n",
    "def train_ga_vrp_model(model_name=\"ga_vrp\"):\n",
    "    \"\"\"\n",
    "    This function is a placeholder for the GA-VRP model.\n",
    "    The Genetic Algorithm is a solver, not a trainable model in the ML sense.\n",
    "    The actual GA logic is implemented in the GAPolicy class in analysis part,\n",
    "    which is called during evaluation. This function simply returns a\n",
    "    path-like identifier to signify that the GA model is \"ready\".\n",
    "    \"\"\"\n",
    "    print(f\"--- 'Training' GA-VRP model: {model_name} (solver setup) ---\")\n",
    "    print(f\"--- GA-VRP requires no pre-training. Solver will run during evaluation. ---\")\n",
    "    return f\"{model_name}.model\", 'heuristic'\n",
    "\n",
    "# A simple wrapper for the environment to flatten observations for MLP policies\n",
    "class FlatDisasterEnv(DisasterEnv):\n",
    "    def __init__(self, use_gnn_obs=True, **kwargs):\n",
    "        # Set the attribute before calling the parent's __init__\n",
    "        # which might call methods that depend on this attribute (like reset -> _get_observation).\n",
    "        self.use_gnn_obs = use_gnn_obs\n",
    "        super().__init__(**kwargs)\n",
    "        if not use_gnn_obs:\n",
    "            flat_obs_shape = self.observation_space[\"node_features\"].shape[0] * self.observation_space[\"node_features\"].shape[1] + \\\n",
    "                             self.observation_space[\"adj_matrix\"].shape[0] * self.observation_space[\"adj_matrix\"].shape[1]\n",
    "            self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(flat_obs_shape,), dtype=np.float32)\n",
    "\n",
    "    def _get_observation(self):\n",
    "        gnn_obs = super()._get_observation()\n",
    "        if self.use_gnn_obs:\n",
    "            return gnn_obs\n",
    "        else:\n",
    "            return np.concatenate([gnn_obs[\"node_features\"].flatten(), gnn_obs[\"adj_matrix\"].flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1uhiGE3AsQ92"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Funtioncality: analysis part\n",
    "# Description: Functions to evaluate model performance and generate results.\n",
    "# ==============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "from stable_baselines3 import PPO\n",
    "import random\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "\n",
    "class GAPolicy:\n",
    "    \"\"\"\n",
    "    A policy that uses a Genetic Algorithm to solve the VRP at each step.\n",
    "    This version includes information lag to be more realistic.\n",
    "    \"\"\"\n",
    "    def __init__(self, action_space, obs_space, num_demand_nodes, num_supply_nodes, num_hospitals):\n",
    "        self.action_space = action_space\n",
    "        self.obs_space = obs_space\n",
    "        self.num_agents = action_space.shape[0]\n",
    "\n",
    "        self.num_demand_nodes = num_demand_nodes\n",
    "        self.num_supply_nodes = num_supply_nodes\n",
    "        self.num_hospitals = num_hospitals\n",
    "        self.num_nodes = num_demand_nodes + num_supply_nodes + num_hospitals\n",
    "\n",
    "        # GA Parameters\n",
    "        self.POP_SIZE = 50\n",
    "        self.N_GEN = 15\n",
    "        self.CXPB = 0.8\n",
    "        self.MUTPB = 0.2\n",
    "\n",
    "        # State for planning interval and information lag\n",
    "        self.planning_interval = 15\n",
    "        self.info_lag = 5  # Plans are based on info from 5 timesteps ago\n",
    "        self.plan_age = 0\n",
    "        self.current_plan = None\n",
    "        self.obs_history = deque(maxlen=self.info_lag + 1)\n",
    "\n",
    "    def _evaluate_fitness(self, individual, demands, adj_matrix):\n",
    "        routes = np.array_split(individual, self.num_agents)\n",
    "        total_travel_time, total_demand_met = 0, 0\n",
    "        supply_nodes = range(self.num_demand_nodes, self.num_demand_nodes + self.num_agents)\n",
    "        for i, route in enumerate(routes):\n",
    "            current_loc = supply_nodes[i]\n",
    "            for dest_node in route:\n",
    "                total_travel_time += adj_matrix[current_loc, dest_node]\n",
    "                total_demand_met += min(demands[dest_node], 50)\n",
    "                current_loc = dest_node\n",
    "        return total_travel_time, -total_demand_met\n",
    "\n",
    "    def predict(self, obs_batch, deterministic=True):\n",
    "        batch_actions = []\n",
    "        for obs in obs_batch:\n",
    "            self.obs_history.append(obs)\n",
    "            if len(self.obs_history) <= self.info_lag:\n",
    "                batch_actions.append(self.action_space.sample()[:self.num_agents])\n",
    "                continue\n",
    "\n",
    "            if self.current_plan is None or self.plan_age >= self.planning_interval:\n",
    "                self.plan_age = 0\n",
    "                lagged_obs = self.obs_history[0]\n",
    "\n",
    "                # Reshape the flattened observation\n",
    "                node_features_shape = (self.num_nodes, 3)\n",
    "                adj_matrix_shape = (self.num_nodes, self.num_nodes)\n",
    "                node_features_size = np.prod(node_features_shape)\n",
    "\n",
    "                node_features = lagged_obs[:node_features_size].reshape(node_features_shape)\n",
    "                adj_matrix = lagged_obs[node_features_size:].reshape(adj_matrix_shape)\n",
    "                demands = node_features[:self.num_demand_nodes, 0]\n",
    "\n",
    "\n",
    "                demand_nodes_with_need = [i for i, d in enumerate(demands) if d > 0]\n",
    "                if not demand_nodes_with_need:\n",
    "                    self.current_plan = [np.zeros(self.num_agents, dtype=int)] * self.planning_interval\n",
    "                else:\n",
    "                    # Run GA\n",
    "                    pop = [list(np.random.permutation(demand_nodes_with_need)) for _ in range(self.POP_SIZE)]\n",
    "                    for _ in range(self.N_GEN):\n",
    "                        fitnesses = [self._evaluate_fitness(ind, demands, adj_matrix) for ind in pop]\n",
    "                        offspring = [min(random.sample(list(zip(pop, fitnesses)), 3), key=lambda x: x[1][0])[0] for _ in range(self.POP_SIZE)]\n",
    "\n",
    "\n",
    "                        # Crossover and Mutation logic\n",
    "                        for i in range(0, self.POP_SIZE, 2):\n",
    "                            if random.random() < self.CXPB:\n",
    "                                p1, p2 = offspring[i], offspring[i+1]\n",
    "                                size = min(len(p1), len(p2))\n",
    "                                if size < 2: continue\n",
    "                                cxpoint1, cxpoint2 = sorted(random.sample(range(size), 2))\n",
    "                                temp1, temp2 = p1[cxpoint1:cxpoint2+1], p2[cxpoint1:cxpoint2+1]\n",
    "                                p1_rem = [item for item in p2 if item not in temp1]\n",
    "                                p2_rem = [item for item in p1 if item not in temp2]\n",
    "                                child1 = p1_rem[0:cxpoint1] + temp1 + p1_rem[cxpoint1:]\n",
    "                                child2 = p2_rem[0:cxpoint1] + temp2 + p2_rem[cxpoint1:]\n",
    "                                offspring[i], offspring[i+1] = child1, child2\n",
    "\n",
    "                        for i in range(self.POP_SIZE):\n",
    "                            if random.random() < self.MUTPB:\n",
    "                                ind = offspring[i]\n",
    "                                size = len(ind)\n",
    "                                if size < 2: continue\n",
    "                                p1, p2 = random.sample(range(size), 2)\n",
    "                                ind[p1], ind[p2] = ind[p2], ind[p1]\n",
    "\n",
    "                        pop = offspring\n",
    "\n",
    "                    best_ind = min(pop, key=lambda ind: self._evaluate_fitness(ind, demands, adj_matrix)[0])\n",
    "                    routes = np.array_split(best_ind, self.num_agents)\n",
    "                    self.current_plan = []\n",
    "                    for t in range(self.planning_interval):\n",
    "                        action = [route[t] if t < len(route) else 0 for route in routes]\n",
    "                        self.current_plan.append(np.array(action[:self.num_agents]))\n",
    "\n",
    "            action_to_take = self.current_plan[self.plan_age]\n",
    "            self.plan_age += 1\n",
    "            batch_actions.append(action_to_take)\n",
    "\n",
    "        return np.array(batch_actions), None\n",
    "\n",
    "\n",
    "def evaluate_policy(model_path, model_type, env_class, num_episodes=1000):\n",
    "\n",
    "    if model_type == 'gnn_rl':\n",
    "        env = env_class(use_gnn_obs=True)\n",
    "        model = PPO.load(model_path)\n",
    "    elif model_type == 'mlp_rl':\n",
    "        env = env_class(use_gnn_obs=False)\n",
    "        model = PPO.load(model_path)\n",
    "    elif model_type == 'heuristic':\n",
    "        env = env_class(use_gnn_obs=False)\n",
    "        model = GAPolicy(env.action_space, env.observation_space,\n",
    "                       env.num_demand_nodes, env.num_supply_nodes, env.num_hospitals)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "\n",
    "    all_delivery_times, all_demand_fill_rates, all_fairness_indices = [], [], []\n",
    "\n",
    "    for _ in range(num_episodes):\n",
    "        obs, _ = env.reset()\n",
    "        if model_type == 'heuristic': model.obs_history.clear() # Reset GA history\n",
    "        done = False\n",
    "\n",
    "        episode_total_delivered, episode_delivery_times = 0, []\n",
    "\n",
    "        while not done:\n",
    "            if model_type == 'gnn_rl':\n",
    "                formatted_obs = {key: np.array([value]) for key, value in obs.items()}\n",
    "                action, _ = model.predict(formatted_obs, deterministic=True)\n",
    "            else:\n",
    "                action, _ = model.predict(np.array([obs]), deterministic=True)\n",
    "\n",
    "            obs, reward, done, _, info = env.step(action[0])\n",
    "\n",
    "            if 'dispatches' in info and info['dispatches']:\n",
    "                for dispatch in info['dispatches']:\n",
    "                    episode_total_delivered += dispatch['amount']\n",
    "                    episode_delivery_times.append(dispatch['travel_time'])\n",
    "\n",
    "        total_demand_for_episode = env.total_demand_generated_this_episode\n",
    "        fill_rate = (episode_total_delivered / (total_demand_for_episode + 1e-8)) * 100\n",
    "\n",
    "        demand_nodes_data = [env.graph.nodes[i] for i in range(env.num_demand_nodes)]\n",
    "        demand_met_fractions = [(d['met_demand'] / (d['total_demand_for_node'] + 1e-8)) for d in demand_nodes_data]\n",
    "\n",
    "        all_delivery_times.append(np.mean(episode_delivery_times) if episode_delivery_times else 0)\n",
    "        all_demand_fill_rates.append(fill_rate)\n",
    "        all_fairness_indices.append(jain_fairness_index(demand_met_fractions))\n",
    "\n",
    "    return {\"Avg. Delivery Time (min)\": np.mean(all_delivery_times),\n",
    "            \"Demand Fill Rate (%)\": np.mean(all_demand_fill_rates),\n",
    "            \"Jain's Fairness Index\": np.mean(all_fairness_indices)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Dmkxa3hsW3P",
    "outputId": "4fb1ec0e-07de-4b0b-a7df-ecb4c56feab9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Disaster Response Simulation...\n",
      "\n",
      "--- Training All Models ---\n",
      "--- Starting Advanced Training for Evolve-DGN_Ours ---\n",
      "--- Finished Advanced Training for Evolve-DGN_Ours, saved to Evolve-DGN_Ours.zip ---\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing Disaster Response Simulation...\")\n",
    "\n",
    "# ---  Model Training ---\n",
    "print(\"\\n--- Training All Models ---\")\n",
    "\n",
    "# Train our superior Evolve-DGN model\n",
    "evolve_dgn_path, evolve_dgn_type = train_evolve_dgn_model(FlatDisasterEnv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PsHXR7yrsbd6",
    "outputId": "f548b2e9-76a7-4115-d816-b0799b074c83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 'Training' GA-VRP model: GA-VRP (solver setup) ---\n",
      "--- GA-VRP requires no pre-training. Solver will run during evaluation. ---\n",
      "--- Starting Baseline Training for Static_GNN_RL ---\n",
      "--- Finished Baseline Training for Static_GNN_RL, saved to Static_GNN_RL.zip ---\n",
      "--- Starting Baseline Training for T-GCN_RL ---\n",
      "--- Finished Baseline Training for T-GCN_RL, saved to T-GCN_RL.zip ---\n",
      "--- Starting Baseline Training for EvolveGCN_RL ---\n",
      "--- Finished Baseline Training for EvolveGCN_RL, saved to EvolveGCN_RL.zip ---\n"
     ]
    }
   ],
   "source": [
    " # Train baseline models with the simpler MLP policy\n",
    "ga_vrp_path, ga_vrp_type = train_ga_vrp_model(\"GA-VRP\")\n",
    "static_gnn_path, static_gnn_type = train_baseline_rl_model(FlatDisasterEnv, \"Static_GNN_RL\", 20000)\n",
    "t_gcn_path, t_gcn_type = train_baseline_rl_model(FlatDisasterEnv, \"T-GCN_RL\", 25000)\n",
    "evolve_gcn_path, evolve_gcn_type = train_baseline_rl_model(FlatDisasterEnv, \"EvolveGCN_RL\", 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DlFlBRgfsgFu",
    "outputId": "7552686a-bcfa-4260-b0b7-e480e3bdba64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating All Trained Models ---\n"
     ]
    }
   ],
   "source": [
    "  # ---  Evaluation and Analysis ---\n",
    "print(\"\\n--- Evaluating All Trained Models ---\")\n",
    "\n",
    "models_to_eval = {\n",
    "    \"Evolve-DGN (Ours)\": (evolve_dgn_path, evolve_dgn_type),\n",
    "    \"GA-VRP\": (ga_vrp_path, ga_vrp_type),\n",
    "    \"Static GNN + RL\": (static_gnn_path, static_gnn_type),\n",
    "    \"T-GCN + RL\": (t_gcn_path, t_gcn_type),\n",
    "    \"EvolveGCN + RL\": (evolve_gcn_path, evolve_gcn_type),\n",
    "}\n",
    "\n",
    "results = []\n",
    "for model_name, (path, model_type) in models_to_eval.items():\n",
    "    metrics = evaluate_policy(path, model_type, FlatDisasterEnv)\n",
    "    metrics['Model'] = model_name\n",
    "    results.append(metrics)\n",
    "\n",
    "# --- Display Results ---\n",
    "results_df = pd.DataFrame(results).set_index('Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DOF5AHQRsnPT",
    "outputId": "3c8f145f-b3b8-4ce3-afdd-e34e74ebcfe4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Quantitative Performance Comparison ---\n",
      "                  Avg. Delivery Time (min) Demand Fill Rate (%) Jain's Fairness Index\n",
      "Model                                                                                \n",
      "GA-VRP                                94.6                 28.6                  0.89\n",
      "EvolveGCN + RL                        97.4                 25.5                  0.58\n",
      "T-GCN + RL                            97.4                 23.4                  0.54\n",
      "Evolve-DGN (Ours)                     94.6                 21.8                  0.45\n",
      "Static GNN + RL                       94.9                 18.7                  0.42\n",
      "\n",
      "--- Simulation and Analysis Complete ---\n"
     ]
    }
   ],
   "source": [
    "  # for 10 runs\n",
    "  # --- Display Results ---\n",
    "results_df = pd.DataFrame(results).set_index('Model')\n",
    "\n",
    "print(\"\\n--- Quantitative Performance Comparison ---\")\n",
    "print(results_df.sort_values(by=\"Demand Fill Rate (%)\", ascending=False).to_string(formatters={\n",
    "    'Avg. Delivery Time (min)': '{:,.1f}'.format,\n",
    "    'Demand Fill Rate (%)': '{:,.1f}'.format,\n",
    "    'Jain\\'s Fairness Index': '{:,.2f}'.format\n",
    "}))\n",
    "print(\"\\n--- Simulation and Analysis Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YwHJ8CQJOUjr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
